{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSYuwqlVxLMy"
      },
      "source": [
        "# Project: Decision trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB73_MRtsmd5"
      },
      "source": [
        "#<font color='teal'>Index</font>\n",
        "\n",
        "- [Basic operations](#basic)\n",
        "- [Merging the additional data with our two main dataframes](#merging)\n",
        "- [Further data processing](#further)\n",
        "- [Models!](#models)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAIjfH7YwptA"
      },
      "source": [
        "<a name=\"basic\"></a>\n",
        "# <font color='blue'> Basic operations:</font>\n",
        "\n",
        "<font color='red'>*You can skip this section and directly load the prepared data*</font>\n",
        "\n",
        "In this group of blocks, we:\n",
        "- Import packages\n",
        "- Load the different files containing the data\n",
        "- Do a quick analysis on the case\n",
        "- Make data management simpler\n",
        "- Deal with datetime columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR6m4inUwptB"
      },
      "source": [
        "## Importing main packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCDu75jWwptB",
        "outputId": "c466b5b4-8e35-4369-a610-4298364d1c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/CM1_CM2_learning/CML_materials/ensembles/kaggle')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import datetime as dt\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "\n",
        "import itertools\n",
        "from math import floor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejuG58xlwptC"
      },
      "source": [
        "## Loading the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF8rU-HzwptC"
      },
      "source": [
        "We call:\n",
        "- Train set = data\n",
        "- Test set = test_data\n",
        "- Additional info = comorbidities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jX3qSwwnwptC"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('mimic_train.csv')\n",
        "test_data = pd.read_csv('mimic_test_los.csv')\n",
        "comorbidities = pd.read_csv('extra_data/MIMIC_diagnoses.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Q7s1eXIqAs"
      },
      "source": [
        "## Quick analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEX3P9naJ3-y"
      },
      "source": [
        "How does `LOS` look like?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "51UKOpGpJ2_3",
        "outputId": "a1f5a5df-50c9-4fa8-a7a6-900efadfc22d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5ea0580910>]],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.hist(column=\"LOS\", bins = 100, range = (0, 5), density = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65RKQlKX_goY",
        "outputId": "8eaff3ca-f253-4b48-8643-3dee86b97f84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    20885.000000\n",
              "mean         3.701046\n",
              "std          5.175721\n",
              "min          0.056600\n",
              "25%          1.165400\n",
              "50%          2.020800\n",
              "75%          3.915800\n",
              "max        101.739000\n",
              "Name: LOS, dtype: float64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"LOS\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLv0EcqxK4R3"
      },
      "source": [
        "Is the chance of dying a feature that would be nice to have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "xdddzTM52V1w",
        "outputId": "0603f4b6-3d1d-44c0-ca99-3845bb102f5d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dies = data[data[\"HOSPITAL_EXPIRE_FLAG\"] ==1][\"LOS\"]\n",
        "surv = data[data[\"HOSPITAL_EXPIRE_FLAG\"] ==0][\"LOS\"]\n",
        "plt.hist(dies, alpha=0.4, density= True, bins = 500, color = \"red\")\n",
        "plt.hist(surv, alpha=0.5, density= True, bins = 2500, color = \"green\")\n",
        "plt.xlim(0,5)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0D3K6ciSDh4"
      },
      "source": [
        "Yes, since the distributions are quite different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCn5fli5LCur"
      },
      "source": [
        "Is the fact that the patient has come before a feature that we would like to have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "CwMksCev-RM8",
        "outputId": "a9a15687-5c96-47c1-c47b-b36c79930d3b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data0 = data.sort_values([\"subject_id\", \"ADMITTIME\"])\n",
        "\n",
        "rep = data0[data0[\"subject_id\"].map(data0[\"subject_id\"].value_counts()) >1]\n",
        "non_rep = data0[data0[\"subject_id\"].map(data0[\"subject_id\"].value_counts()) == 1]\n",
        "\n",
        "\n",
        "plt.hist(rep[\"LOS\"], alpha=0.5, density= True, bins = 1000, color = \"blue\")\n",
        "plt.hist(non_rep[\"LOS\"], alpha=0.5, density= True, bins = 1000, color = \"green\")\n",
        "plt.xlim(0,5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iyUDLIsSYMh"
      },
      "source": [
        "Yes, repeat patients seem to have longer lengths of stay, the effect is more subtle than deaths though."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERayXkXQwptC"
      },
      "source": [
        "## Making data management simpler:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Toy9GWTwptC"
      },
      "source": [
        "We rename some columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7DiYIQUwptC"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={'ICD9_diagnosis': 'ICD9_CODE'}, inplace=True)\n",
        "test_data.rename(columns={'ICD9_diagnosis': 'ICD9_CODE'}, inplace=True)\n",
        "\n",
        "data.rename(columns={'hadm_id': 'HADM_ID'}, inplace=True)\n",
        "test_data.rename(columns={'hadm_id': 'HADM_ID'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVMG_p8UV56z"
      },
      "source": [
        "We remove from the extra data, that which is about patients we do not have in our train or test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78ZevRgVV0ew"
      },
      "outputs": [],
      "source": [
        "unique_patients_in_data = list(data['subject_id'].unique())\n",
        "unique_patients_in_test_data = list(test_data['subject_id'].unique())\n",
        "unique_patients = unique_patients_in_data + unique_patients_in_test_data\n",
        "comorbidities = comorbidities.loc[comorbidities['SUBJECT_ID'].isin(unique_patients)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD7_2WrGwptD"
      },
      "source": [
        "## Dealing with datetime columns:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXoxpn6HwptD"
      },
      "source": [
        "### We generate a column for the patient's age at admission time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wESQTQAUwptD"
      },
      "outputs": [],
      "source": [
        "# Function to compute and create a column for Age:\n",
        "def get_age(df):\n",
        "\n",
        "  a = list(range(0, df.shape[0], 1))\n",
        "  age_col = []\n",
        "  for i in a:\n",
        "    dif1 = relativedelta(pd.to_datetime(df['ADMITTIME'][i]), pd.to_datetime(df['DOB'][i])).years\n",
        "    dif2 = relativedelta(pd.to_datetime(df['ADMITTIME'][i]), pd.to_datetime(df['DOB'][i])).months\n",
        "    dif3 = relativedelta(pd.to_datetime(df['ADMITTIME'][i]), pd.to_datetime(df['DOB'][i])).days\n",
        "    dif = dif1 + dif2/12+dif3/365.25\n",
        "    if dif > 120: #to normalize those with odd DOBs, who are 90 or older\n",
        "      dif = 90\n",
        "    age_col.append(dif)\n",
        "  \n",
        "  df['Age'] = age_col\n",
        "  \n",
        "  return df\n",
        "\n",
        "for i in [data, test_data]:\n",
        "  get_age(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lIRgR5ZpFYq"
      },
      "source": [
        "### We correct the datetime offset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8tYGQ_ppWOY"
      },
      "outputs": [],
      "source": [
        "# Function to solve the datetimes offset:\n",
        "def datetime_diff(df):\n",
        "  \n",
        "  df[\"DOB\"] = pd.to_datetime(df[\"DOB\"])\n",
        "  df[\"DOB\"] = df.apply(lambda x: x[\"DOB\"] + pd.DateOffset(days=x[\"Diff\"]), axis=1)\n",
        "  df[\"DOB\"] = df[\"DOB\"].dt.floor(\"Min\").dt.strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "  df[\"ADMITTIME\"] = pd.to_datetime(df[\"ADMITTIME\"])\n",
        "  df[\"ADMITTIME\"] = df.apply(lambda x: x[\"ADMITTIME\"] + pd.DateOffset(days=x[\"Diff\"]), axis=1)\n",
        "  df[\"ADMITTIME\"] = df[\"ADMITTIME\"].dt.floor(\"Min\").dt.strftime(\"%Y-%m-%d %H:%M\")\n",
        "\n",
        "  return df\n",
        "\n",
        "for i in [data, test_data]:\n",
        "  datetime_diff(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c6rMEEOqf5a"
      },
      "source": [
        "### We generate more features out of `ADMITTIME`:\n",
        "\n",
        "| New Feature | What is the idea?\n",
        "|----------|---------------|\n",
        "|Season of admission | Do patients stay longer in winter?         |        \n",
        "|Year of admission | Are there specially complicated years?           |    \n",
        "|Month of admission| Do doctors still have energy by July?       |    \n",
        "|Weekday of admission | Is it more dangerous to be admitted a Sunday than a Wednesday?        |           \n",
        "|Hour of admission | Is it more likely to have to stay a few extra hours if you were admitted at 3am?        |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmrD-Fr9wptD"
      },
      "outputs": [],
      "source": [
        "def season(month):\n",
        "   seasons = [\"Winter\", \"Spring\", \"Summer\", \"Autumn\"]\n",
        "   return seasons[np.floor((month-1)/3)]\n",
        "\n",
        "def time_cols(df):\n",
        "  df[\"ADM_year\"] = pd.DatetimeIndex(df[\"ADMITTIME\"]).year\n",
        "  df[\"ADM_month\"] = pd.DatetimeIndex(df[\"ADMITTIME\"]).month\n",
        "  df[\"ADM_weekday\"] = pd.DatetimeIndex(df[\"ADMITTIME\"]).weekday\n",
        "  df[\"ADM_hour\"] = pd.DatetimeIndex(df[\"ADMITTIME\"]).hour \n",
        "\n",
        "  df[\"ADM_season\"] = df.apply(lambda x: season(x.ADM_month),axis=1)\n",
        "\n",
        "for df in [data, test_data]:\n",
        "  time_cols(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6F7gWNMqaga"
      },
      "source": [
        "### Patients that have been in hospital before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOYgWZECrFHW"
      },
      "outputs": [],
      "source": [
        "#this generates a new column with a 0 if this is the first time the patient is admitted or a 1 if it is not.\n",
        "def rep(df):\n",
        "  data0 = df.sort_values([\"subject_id\", \"ADMITTIME\"])\n",
        "\n",
        "  listita = [0]\n",
        "  for i in list(range(1, df.shape[0])):\n",
        "    if data0.iloc[i,1] == data0.iloc[i-1,1]:\n",
        "      listita.append(1)\n",
        "    else:\n",
        "      listita.append(0)\n",
        "\n",
        "  data0[\"repeat\"] = listita\n",
        "\n",
        "  df = data0\n",
        "  return df.sort_values([\"subject_id\", \"ADMITTIME\"]).sort_index(axis = 0)\n",
        " \n",
        "data = rep(data)\n",
        "test_data = rep(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0iOVx7KtXS8"
      },
      "source": [
        "### Expanding `LOS` to get more features:\n",
        "\n",
        "Of course, `LOS` is what we want to predict. But would it be a good idea to split the prediction into two? For instance:\n",
        "\n",
        "- One model predicts how many days the patient is going to stay.\n",
        "- Another predicts time of discharge.\n",
        "\n",
        "You then join the two for your final `LOS` prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5698rs7tSb3"
      },
      "outputs": [],
      "source": [
        "def open_LOS(df):\n",
        "\n",
        "  df[\"ADMITTIME\"] = pd.to_datetime(df[\"ADMITTIME\"])\n",
        "  df[\"DISCHARGE\"] = df.apply(lambda x: x[\"ADMITTIME\"] + pd.DateOffset(days=x[\"LOS\"]), axis=1)\n",
        "  df[\"DISCHARGE\"] = df[\"DISCHARGE\"].dt.floor(\"Min\").dt.strftime(\"%Y-%m-%d %H:%M\")\n",
        "  df[\"DIS_weekday\"] = pd.DatetimeIndex(df[\"ADMITTIME\"]).weekday\n",
        "  df[\"DIS_hour\"] = pd.DatetimeIndex(df[\"ADMITTIME\"]).hour \n",
        "\n",
        "open_LOS(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "2p7yg8kPwptE",
        "outputId": "8dbb618b-6ca9-473d-c8ba-d5ecc1d4fbf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0365437158469946"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.hist(column=\"DIS_weekday\",bins = 7)\n",
        "max(data[\"DIS_weekday\"].value_counts())/min(data[\"DIS_weekday\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxzRxLh-xf-L"
      },
      "source": [
        "There does not seem to be a day of the week in which being discharged is significantly more/less likely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "qloiKaygxvYt",
        "outputId": "b6801463-847a-4eca-8ff3-2b3b5076d739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1383108935128519"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.hist(column=\"DIS_hour\", bins=6)\n",
        "max(data[\"DIS_hour\"].value_counts())/min(data[\"DIS_hour\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f68d2rf77Lde"
      },
      "source": [
        "Although there is a 13% difference between the less and most frequent hour of discharge, the histogram does not seem to indicate that there is a signal there. We therefore abbandon this idea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iunVvv5SwptE"
      },
      "source": [
        "<a name=\"merging\"></a>\n",
        "\n",
        "# <font color='blue'> Merging the additional data (comorbidities) with our two main dataframes:</font>\n",
        "\n",
        "<font color='red'>*You can skip this section and directly load the prepared data*\n",
        "\n",
        "In this section, we:\n",
        "- Build the dataframes with the data to merge.\n",
        "- Merge the dataframes and further clean.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6yIig4pAcjm"
      },
      "source": [
        "### Adding the number of comorbidities a patient has. `SEQ_NUM`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9GtLC9cwptE",
        "outputId": "a89a9658-02b7-4bba-e1ae-3026b109e03d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20885, 52)\n",
            "(5221, 47)\n"
          ]
        }
      ],
      "source": [
        "dseq = comorbidities[[\"HADM_ID\", \"SEQ_NUM\"]]\n",
        "dseq = dseq.groupby(['HADM_ID'], as_index=False).max()\n",
        "data = data.merge(dseq, on='HADM_ID', how='left')\n",
        "test_data = test_data.merge(dseq, on='HADM_ID', how='left')\n",
        "print(data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teAp7k_DDCnz"
      },
      "source": [
        "## Building the dataframes to later merge:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4onTWNa9Ehqh"
      },
      "source": [
        "The additional data offers the comorbidities people had at the time of admission. \n",
        "\n",
        "We will add this information to our main dataframes considering two types of comorbidities:\n",
        "\n",
        "- Those that help predict probability of death. Here, we consider single comorbidities and also try to capture the synergic effect they have when simultaneously present.\n",
        "\n",
        "- Those that help predict `LOS`, which are not necessarily the same ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeIGEzjewptF"
      },
      "source": [
        "###Single comorbidities:\n",
        "\n",
        "We construct a df of the form:\n",
        "- HADM_ID\n",
        "- Dummified 5849 comorbs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSWj2Po7wptF",
        "outputId": "191a5620-d509-4261-c3a8-6c2a499735ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(385240, 5852)\n"
          ]
        }
      ],
      "source": [
        "de = pd.get_dummies(comorbidities)\n",
        "print(de.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETGQBl3hhA8e"
      },
      "outputs": [],
      "source": [
        "de = de.drop([\"SUBJECT_ID\", \"SEQ_NUM\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVOO1MbdaXOn"
      },
      "source": [
        "The following avoids the program crashing due to RAM limitations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M590j-9EwptF"
      },
      "outputs": [],
      "source": [
        "names = []\n",
        "for i in list(range(1, len(list(de.columns)))):\n",
        "  names.append(list(de.columns)[i][10:])\n",
        "\n",
        "dic = dict(zip(list(de.columns)[1:], names))\n",
        "de = de.rename(columns=dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9siiUFfRwptG"
      },
      "outputs": [],
      "source": [
        "de_1 = de.head(30000)\n",
        "de_1 = de_1.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYO1kEoHwptG"
      },
      "outputs": [],
      "source": [
        "de_2 = de[30000:60000]\n",
        "de_2 = de_2.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpdYBtfuwptG"
      },
      "outputs": [],
      "source": [
        "de_3 = de[60000:100000]\n",
        "de_3 = de_3.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypyRsnSMwptG"
      },
      "outputs": [],
      "source": [
        "de_4 = de[100000:150000]\n",
        "de_4 = de_4.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwlRNJMNiXMP"
      },
      "outputs": [],
      "source": [
        "de_5 = de[150000:200000]\n",
        "de_5 = de_5.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dTJeOehidtt"
      },
      "outputs": [],
      "source": [
        "de_6 = de[200000:250000]\n",
        "de_6 = de_6.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjhDOjcCii7t"
      },
      "outputs": [],
      "source": [
        "de_7 = de[250000:300000]\n",
        "de_7 = de_7.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrFv8H0_iofb"
      },
      "outputs": [],
      "source": [
        "de_8 = de[300000:]\n",
        "de_8 = de_8.groupby(['HADM_ID'], as_index=False).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNSsfoLlwptG",
        "outputId": "48305c63-96c0-4c4c-f15b-44ceb817e2eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27558, 5850)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "de = pd.concat([de_1, de_2, de_3, de_4, de_5, de_6, de_7, de_8])\n",
        "de = de.groupby(['HADM_ID'], as_index=False).sum()\n",
        "de.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "DnwPavPFi_qk",
        "outputId": "6bbebf4c-4923-497c-89e6-497dd5505f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(27558, 5850)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>0030</th>\n",
              "      <th>0031</th>\n",
              "      <th>0038</th>\n",
              "      <th>0039</th>\n",
              "      <th>0041</th>\n",
              "      <th>00581</th>\n",
              "      <th>0059</th>\n",
              "      <th>0071</th>\n",
              "      <th>0074</th>\n",
              "      <th>00804</th>\n",
              "      <th>00841</th>\n",
              "      <th>00843</th>\n",
              "      <th>00845</th>\n",
              "      <th>00847</th>\n",
              "      <th>0085</th>\n",
              "      <th>00862</th>\n",
              "      <th>00863</th>\n",
              "      <th>00869</th>\n",
              "      <th>0088</th>\n",
              "      <th>0090</th>\n",
              "      <th>0091</th>\n",
              "      <th>0092</th>\n",
              "      <th>0093</th>\n",
              "      <th>01123</th>\n",
              "      <th>01164</th>\n",
              "      <th>01186</th>\n",
              "      <th>01190</th>\n",
              "      <th>01194</th>\n",
              "      <th>01205</th>\n",
              "      <th>01300</th>\n",
              "      <th>01304</th>\n",
              "      <th>01325</th>\n",
              "      <th>01330</th>\n",
              "      <th>01354</th>\n",
              "      <th>01402</th>\n",
              "      <th>01405</th>\n",
              "      <th>01485</th>\n",
              "      <th>01504</th>\n",
              "      <th>01505</th>\n",
              "      <th>...</th>\n",
              "      <th>V8489</th>\n",
              "      <th>V850</th>\n",
              "      <th>V851</th>\n",
              "      <th>V8521</th>\n",
              "      <th>V8522</th>\n",
              "      <th>V8523</th>\n",
              "      <th>V8524</th>\n",
              "      <th>V8525</th>\n",
              "      <th>V8530</th>\n",
              "      <th>V8531</th>\n",
              "      <th>V8532</th>\n",
              "      <th>V8533</th>\n",
              "      <th>V8534</th>\n",
              "      <th>V8535</th>\n",
              "      <th>V8536</th>\n",
              "      <th>V8537</th>\n",
              "      <th>V8538</th>\n",
              "      <th>V8539</th>\n",
              "      <th>V854</th>\n",
              "      <th>V8541</th>\n",
              "      <th>V8542</th>\n",
              "      <th>V8543</th>\n",
              "      <th>V8544</th>\n",
              "      <th>V8545</th>\n",
              "      <th>V860</th>\n",
              "      <th>V861</th>\n",
              "      <th>V8709</th>\n",
              "      <th>V872</th>\n",
              "      <th>V8741</th>\n",
              "      <th>V8745</th>\n",
              "      <th>V8801</th>\n",
              "      <th>V8811</th>\n",
              "      <th>V8812</th>\n",
              "      <th>V8821</th>\n",
              "      <th>V9010</th>\n",
              "      <th>V902</th>\n",
              "      <th>V9039</th>\n",
              "      <th>V9081</th>\n",
              "      <th>V9089</th>\n",
              "      <th>V9103</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100009</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100010</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100011</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  5850 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   HADM_ID  0030  0031  0038  0039  ...  V902  V9039  V9081  V9089  V9103\n",
              "0   100001     0     0     0     0  ...     0      0      0      0      0\n",
              "1   100003     0     0     0     0  ...     0      0      0      0      0\n",
              "2   100009     0     0     0     0  ...     0      0      0      0      0\n",
              "3   100010     0     0     0     0  ...     0      0      0      0      0\n",
              "4   100011     0     0     0     0  ...     0      0      0      0      0\n",
              "\n",
              "[5 rows x 5850 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(de.shape)\n",
        "de.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dZKxGUwwptG"
      },
      "source": [
        "### Pairwise interactions - Used for Death prediction:\n",
        "\n",
        "We construct a dataframe of the form:\n",
        "- HADM_ID\n",
        "- Dummified possible combinations between the top 100 deadliest comorbidities (4950 features).\n",
        "- named: de_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvZQW-s1wptG",
        "outputId": "60d0b17d-8bf2-4d78-a3be-94dcd44185d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100% (4950 of 4950) |####################| Elapsed Time: 0:00:28 Time:  0:00:28\n"
          ]
        }
      ],
      "source": [
        "n = 100\n",
        "died = data.loc[data['HOSPITAL_EXPIRE_FLAG'] == 1]\n",
        "who_died = died['HADM_ID']\n",
        "\n",
        "what_kills = comorbidities.loc[comorbidities['HADM_ID'].isin(who_died)]\n",
        "\n",
        "top_killers = what_kills['ICD9_CODE'].value_counts()[:n].index.tolist()\n",
        "\n",
        "all_combinations = list(itertools.combinations(top_killers, 2))\n",
        "\n",
        "\n",
        "name_col = []\n",
        "col_1 = []\n",
        "col_2 = []\n",
        "for (i, j) in all_combinations:\n",
        "  \n",
        "  name_col.append(i+\"+\"+j)\n",
        "  col_1.append(i)\n",
        "  col_2.append(j)\n",
        "dic = {'Pair': name_col, '1': col_1, '2': col_2}\n",
        "\n",
        "dic = pd.DataFrame(dic)\n",
        "\n",
        "num = list(range(0, len(dic['Pair']),1))\n",
        "\n",
        "from progressbar import ProgressBar\n",
        "pbar = ProgressBar()\n",
        "\n",
        "de_pair = de.copy()\n",
        "\n",
        "for i in pbar(num):\n",
        "\n",
        "  de_pair[dic['Pair'][i]] = np.where(de[dic['1'][i]] + de[dic['2'][i]] == 2, 1, 0)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGjcUlLuwptG"
      },
      "source": [
        "### Single comorbidities for Death prediction:\n",
        "Dataframe of the form:\n",
        "- HADM_ID\n",
        "- Dummified top 100 most present comorbilities in those who die\n",
        "- Named: de1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGPQ_pxEwptG"
      },
      "outputs": [],
      "source": [
        "top = 100\n",
        "de1 = de[list(what_kills.ICD9_CODE.value_counts().index)[:top]+[\"HADM_ID\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RNBFqC5Zqph"
      },
      "source": [
        "### Single comorbidities for LOS prediction:\n",
        "We identify the top 150 most relevant comorbidities for LOS. \n",
        "\n",
        "To do so, we divide LOS into Short and Long Stays, considering the median as the threshold: 50% of observations will be of each type.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC983gZzTUsA",
        "outputId": "dc176de0-25f7-42bd-9266-567ce8b31f53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "proportion of short stays:  0.4999281781182667\n"
          ]
        }
      ],
      "source": [
        "data1 = data\n",
        "data1 = data1[[\"HADM_ID\", \"LOS\"]]\n",
        "data1[\"Short_stay\"] = np.where(data1[\"LOS\"] < 2.0208, 1, 0)\n",
        "print(\"proportion of short stays: \", sum(data1[\"Short_stay\"])/len(data1[\"Short_stay\"]))\n",
        "data1 = data1.merge(de, on='HADM_ID', how='left')\n",
        "\n",
        "def most_freq(a):\n",
        "  data2 = data1[data1[\"Short_stay\"] == a]\n",
        "\n",
        "\n",
        "  freqs = []\n",
        "  comorb = list(data2.columns)[3:]\n",
        "  for i in comorb:\n",
        "    freqs.append(sum(data2[i]))\n",
        "\n",
        "\n",
        "  zipped = list(zip(comorb, freqs))\n",
        "  comorb_in_short_stays = pd.DataFrame(zipped, columns=['Comorb', 'Freq'])\n",
        "  \n",
        "  return comorb_in_short_stays\n",
        "\n",
        "ss = most_freq(1)\n",
        "ls = most_freq(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z63GR9Kbk8H1"
      },
      "source": [
        "We now analyse which comorbidities are more present in short and long stays. \n",
        "\n",
        "Since some comorbidities are present in both cases, we generate a ratio between frequencies.\n",
        "We keep only those comorbidities that are 75% more likely to be present in short or long stays:\n",
        "\n",
        "- 10 comorbidities are more likely when the stay is short.\n",
        "- 140 when the stay is long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teyydwJdVd58",
        "outputId": "3d7ce210-98bb-4e69-fcb9-ae1b5ffeffd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(698, 5)\n"
          ]
        }
      ],
      "source": [
        "ss.rename(columns={'Freq': 'Freq_ss'}, inplace=True)\n",
        "ls.rename(columns={'Freq': 'Freq_ls'}, inplace=True)\n",
        "ls1 = ls.drop([\"Comorb\"], axis=1)\n",
        "top_comorbs = pd.concat([ss, ls1], axis=1)\n",
        "top_comorbs = top_comorbs[top_comorbs[\"Freq_ss\"]>25] # to remove infrequent comorbidities\n",
        "top_comorbs = top_comorbs[top_comorbs[\"Freq_ls\"]>25] # to remove infrequent comorbidities\n",
        "top_comorbs[\"sum\"] = top_comorbs[\"Freq_ss\"] + top_comorbs[\"Freq_ls\"]\n",
        "\n",
        "top_comorbs[\"ratio\"] = (top_comorbs[\"Freq_ss\"] / top_comorbs[\"Freq_ls\"])\n",
        "top_comorbs = top_comorbs.sort_values(by=['ratio'], ascending=False)\n",
        "\n",
        "print(top_comorbs.shape)\n",
        "\n",
        "x = 10\n",
        "\n",
        "top_comorbs_ss = list(top_comorbs.head(x)[\"Comorb\"])\n",
        "top_comorbs_ls = list(top_comorbs.tail(150-x)[\"Comorb\"])\n",
        "\n",
        "top_comorbs_stay = top_comorbs_ss + top_comorbs_ls #these are the most relevant comorbidities for LOS prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T8J6WJAF3Is"
      },
      "source": [
        "### Pairwise comorbidities for Death prediction:\n",
        "Dataframe of the form:\n",
        "- HADM_ID\n",
        "- Dummified top 100 most present pair of comorbilities in those who die\n",
        "- Named: de_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRPhZGNhwptH",
        "outputId": "11256ca3-22a2-4a95-ef58-6dd73bcbd198"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>0030</th>\n",
              "      <th>0031</th>\n",
              "      <th>0038</th>\n",
              "      <th>0039</th>\n",
              "      <th>0041</th>\n",
              "      <th>00581</th>\n",
              "      <th>0059</th>\n",
              "      <th>0071</th>\n",
              "      <th>0074</th>\n",
              "      <th>00804</th>\n",
              "      <th>00841</th>\n",
              "      <th>00843</th>\n",
              "      <th>00845</th>\n",
              "      <th>00847</th>\n",
              "      <th>0085</th>\n",
              "      <th>00862</th>\n",
              "      <th>00863</th>\n",
              "      <th>00869</th>\n",
              "      <th>0088</th>\n",
              "      <th>0090</th>\n",
              "      <th>0091</th>\n",
              "      <th>0092</th>\n",
              "      <th>0093</th>\n",
              "      <th>01123</th>\n",
              "      <th>01164</th>\n",
              "      <th>01186</th>\n",
              "      <th>01190</th>\n",
              "      <th>01194</th>\n",
              "      <th>01205</th>\n",
              "      <th>01300</th>\n",
              "      <th>01304</th>\n",
              "      <th>01325</th>\n",
              "      <th>01330</th>\n",
              "      <th>01354</th>\n",
              "      <th>01402</th>\n",
              "      <th>01405</th>\n",
              "      <th>01485</th>\n",
              "      <th>01504</th>\n",
              "      <th>01505</th>\n",
              "      <th>...</th>\n",
              "      <th>5722+V1254</th>\n",
              "      <th>5722+42832</th>\n",
              "      <th>5722+30000</th>\n",
              "      <th>5722+79092</th>\n",
              "      <th>99591+43491</th>\n",
              "      <th>99591+2930</th>\n",
              "      <th>99591+V103</th>\n",
              "      <th>99591+2639</th>\n",
              "      <th>99591+V1254</th>\n",
              "      <th>99591+42832</th>\n",
              "      <th>99591+30000</th>\n",
              "      <th>99591+79092</th>\n",
              "      <th>43491+2930</th>\n",
              "      <th>43491+V103</th>\n",
              "      <th>43491+2639</th>\n",
              "      <th>43491+V1254</th>\n",
              "      <th>43491+42832</th>\n",
              "      <th>43491+30000</th>\n",
              "      <th>43491+79092</th>\n",
              "      <th>2930+V103</th>\n",
              "      <th>2930+2639</th>\n",
              "      <th>2930+V1254</th>\n",
              "      <th>2930+42832</th>\n",
              "      <th>2930+30000</th>\n",
              "      <th>2930+79092</th>\n",
              "      <th>V103+2639</th>\n",
              "      <th>V103+V1254</th>\n",
              "      <th>V103+42832</th>\n",
              "      <th>V103+30000</th>\n",
              "      <th>V103+79092</th>\n",
              "      <th>2639+V1254</th>\n",
              "      <th>2639+42832</th>\n",
              "      <th>2639+30000</th>\n",
              "      <th>2639+79092</th>\n",
              "      <th>V1254+42832</th>\n",
              "      <th>V1254+30000</th>\n",
              "      <th>V1254+79092</th>\n",
              "      <th>42832+30000</th>\n",
              "      <th>42832+79092</th>\n",
              "      <th>30000+79092</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>100061</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>100074</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>100098</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>100197</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>100223</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  10800 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    HADM_ID  0030  0031  ...  42832+30000  42832+79092  30000+79092\n",
              "23   100061     0     0  ...            0            0            0\n",
              "28   100074     0     0  ...            0            0            0\n",
              "35   100098     0     0  ...            0            0            0\n",
              "57   100197     0     0  ...            0            0            0\n",
              "65   100223     0     0  ...            0            0            0\n",
              "\n",
              "[5 rows x 10800 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "de_pair1 = de_pair[de_pair['HADM_ID'].isin(who_died)]\n",
        "de_pair1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMLcjXvbwptH",
        "outputId": "0a99883d-8521-46a3-f512-7e9cdc7c2e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2093\n"
          ]
        }
      ],
      "source": [
        "leave = 100\n",
        "\n",
        "print(len((who_died.unique())))\n",
        "de_pair1 = de_pair[de_pair['HADM_ID'].isin(who_died)]\n",
        "sums = []\n",
        "for i in list(de_pair1.columns)[5850:]:\n",
        "  sums.append(de_pair1[i].sum())\n",
        "auxdf = pd.DataFrame({\"ColName\": list(de_pair1.columns)[5850:], \"Sum\": sums})\n",
        "auxdf = auxdf.sort_values(by=\"Sum\", ascending=False)\n",
        "auxdf = auxdf.head(leave)\n",
        "leave_these_columns = ['HADM_ID'] + list(auxdf['ColName'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8uUlAejwptH",
        "outputId": "8a238213-8d56-4ecc-bf39-9a6f66748cab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>99592+0389</th>\n",
              "      <th>99592+78552</th>\n",
              "      <th>51881+99592</th>\n",
              "      <th>51881+5849</th>\n",
              "      <th>42731+4280</th>\n",
              "      <th>51881+4019</th>\n",
              "      <th>51881+42731</th>\n",
              "      <th>51881+0389</th>\n",
              "      <th>0389+78552</th>\n",
              "      <th>5849+99592</th>\n",
              "      <th>51881+4280</th>\n",
              "      <th>51881+78552</th>\n",
              "      <th>51881+2762</th>\n",
              "      <th>4019+42731</th>\n",
              "      <th>5849+4280</th>\n",
              "      <th>42731+5849</th>\n",
              "      <th>4019+5849</th>\n",
              "      <th>99592+2762</th>\n",
              "      <th>5849+2762</th>\n",
              "      <th>4019+2724</th>\n",
              "      <th>42731+99592</th>\n",
              "      <th>5849+0389</th>\n",
              "      <th>51881+486</th>\n",
              "      <th>99592+4280</th>\n",
              "      <th>4019+25000</th>\n",
              "      <th>51881+25000</th>\n",
              "      <th>5849+78552</th>\n",
              "      <th>4019+99592</th>\n",
              "      <th>40390+5859</th>\n",
              "      <th>4019+4280</th>\n",
              "      <th>42731+2762</th>\n",
              "      <th>2762+0389</th>\n",
              "      <th>51881+V4986</th>\n",
              "      <th>4019+2762</th>\n",
              "      <th>4280+41401</th>\n",
              "      <th>51881+2724</th>\n",
              "      <th>4019+V4986</th>\n",
              "      <th>42731+V5861</th>\n",
              "      <th>42731+2724</th>\n",
              "      <th>...</th>\n",
              "      <th>99592+5845</th>\n",
              "      <th>5849+40390</th>\n",
              "      <th>4280+78552</th>\n",
              "      <th>4019+41401</th>\n",
              "      <th>5849+2724</th>\n",
              "      <th>4280+486</th>\n",
              "      <th>5849+5990</th>\n",
              "      <th>4280+5859</th>\n",
              "      <th>51881+2875</th>\n",
              "      <th>99592+486</th>\n",
              "      <th>42731+486</th>\n",
              "      <th>5849+V4986</th>\n",
              "      <th>5849+5859</th>\n",
              "      <th>5849+41401</th>\n",
              "      <th>2762+5845</th>\n",
              "      <th>51881+4275</th>\n",
              "      <th>42731+40390</th>\n",
              "      <th>4019+78552</th>\n",
              "      <th>V4986+2724</th>\n",
              "      <th>42731+5990</th>\n",
              "      <th>99592+25000</th>\n",
              "      <th>2724+25000</th>\n",
              "      <th>4280+V4986</th>\n",
              "      <th>5849+V667</th>\n",
              "      <th>0389+486</th>\n",
              "      <th>99592+2875</th>\n",
              "      <th>2724+41401</th>\n",
              "      <th>4019+486</th>\n",
              "      <th>51881+40390</th>\n",
              "      <th>4280+V5861</th>\n",
              "      <th>51881+2760</th>\n",
              "      <th>42731+V667</th>\n",
              "      <th>5849+2875</th>\n",
              "      <th>51881+2761</th>\n",
              "      <th>99592+5990</th>\n",
              "      <th>78552+5845</th>\n",
              "      <th>42731+5859</th>\n",
              "      <th>42731+5845</th>\n",
              "      <th>2762+25000</th>\n",
              "      <th>51881+496</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   HADM_ID  99592+0389  99592+78552  ...  42731+5845  2762+25000  51881+496\n",
              "0   100001           0            0  ...           0           0          0\n",
              "1   100003           0            0  ...           0           0          0\n",
              "\n",
              "[2 rows x 101 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "de_pair = de_pair[leave_these_columns]\n",
        "de_pair.head(2)\n",
        "#de_pair['99592+0389'].sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alep3fdGwptH"
      },
      "source": [
        "## Merging the dataframes and further cleaning:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7INwBU1BbYaP"
      },
      "source": [
        "At this point, we add to the main dataframes the addition information relevant for Death prediction. Later on, we will remove these features and add those pertinent for LOS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOLWwBmbwptH",
        "outputId": "7371d8da-b53f-493a-f7c0-0df3b10ab27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data was: (20885, 52)\n",
            "test_data was: (5221, 47)\n",
            "data now is: (20885, 252)\n",
            "test_data now is: (5221, 247)\n"
          ]
        }
      ],
      "source": [
        "print(\"data was: \" + str(data.shape))\n",
        "print(\"test_data was: \" + str(test_data.shape))\n",
        "data = data.merge(de1, on='HADM_ID', how='left')\n",
        "data = data.merge(de_pair, on='HADM_ID', how='left')\n",
        "\n",
        "test_data = test_data.merge(de1, on='HADM_ID', how='left')\n",
        "test_data = test_data.merge(de_pair, on='HADM_ID', how='left')\n",
        "\n",
        "print(\"data now is: \" + str(data.shape))\n",
        "print(\"test_data now is: \" + str(test_data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4SK_t3qwptH"
      },
      "source": [
        "Since the training data has more columns than the test data, we remove those which do not intersect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpaHCGtYwptI",
        "outputId": "365d7d62-6ae9-44c2-d691-110da5d24458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data was: (20885, 252)\n",
            "test_data was: (5221, 247)\n",
            "data now is: (20885, 249)\n",
            "test_data now is: (5221, 247)\n"
          ]
        }
      ],
      "source": [
        "print(\"data was: \" + str(data.shape))\n",
        "print(\"test_data was: \" + str(test_data.shape))\n",
        "a = list(data.columns)\n",
        "b = list(test_data.columns)\n",
        "all_columns = a + b \n",
        "\n",
        "unique_columns = [i for i in all_columns if all_columns.count(i)==1]\n",
        "\n",
        "unique_columns.remove(\"HOSPITAL_EXPIRE_FLAG\")\n",
        "unique_columns.remove(\"LOS\")\n",
        "data = data.drop(unique_columns, axis=1)\n",
        "\n",
        "print(\"data now is: \" + str(data.shape))\n",
        "print(\"test_data now is: \" + str(test_data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNPzAJSrwptI"
      },
      "source": [
        "We drop some features, from both the training and test data, that are no longer useful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emcXc1yDwptI"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['subject_id', 'icustay_id', \"DOB\", \"Diff\", \"ADMITTIME\", \"DIAGNOSIS\", \"ICD9_CODE\"], axis=1)\n",
        "test_data = test_data.drop(['subject_id', 'icustay_id', \"DOB\", \"Diff\", \"ADMITTIME\", \"DIAGNOSIS\", \"ICD9_CODE\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TOaCNLwptI"
      },
      "source": [
        "<a name=\"further\"></a>\n",
        "# <font color='blue'> Further data processing:</font>\n",
        "\n",
        "<font color='red'>*You can skip this section and directly load the prepared data*\n",
        "\n",
        "In this group of blocks, we deal with:\n",
        "\n",
        "- Missing data\n",
        "- Categorical features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmhkspj8wptI"
      },
      "source": [
        "## Dealing with missing data (NAs):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9QiegeCwptI"
      },
      "source": [
        "We check for null values in data and test_data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN2p9wjnwptI",
        "outputId": "6cf45410-1acd-49d0-8ecb-ab8abc66652c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HOSPITAL_EXPIRE_FLAG       0\n",
            "HADM_ID                    0\n",
            "HeartRate_Min           2187\n",
            "HeartRate_Max           2187\n",
            "HeartRate_Mean          2187\n",
            "                        ... \n",
            "78552+5845                 0\n",
            "42731+5859                 0\n",
            "42731+5845                 0\n",
            "2762+25000                 0\n",
            "51881+496                  0\n",
            "Length: 242, dtype: int64\n",
            "HADM_ID             0\n",
            "HeartRate_Min     545\n",
            "HeartRate_Max     545\n",
            "HeartRate_Mean    545\n",
            "SysBP_Min         551\n",
            "                 ... \n",
            "78552+5845          0\n",
            "42731+5859          0\n",
            "42731+5845          0\n",
            "2762+25000          0\n",
            "51881+496           0\n",
            "Length: 240, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "Nulls = data.isnull().sum()\n",
        "print(Nulls)\n",
        "Nulls1 = test_data.isnull().sum()\n",
        "print(Nulls1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjcAAaomwptI"
      },
      "source": [
        "There are many NAs so we will use placeholders, through Sklearn's SimpleImputer.\n",
        "\n",
        "For numerical missing values, the strategy will be to use the mean. This implies replacing every NA, in every column with one, with the mean of that column.\n",
        "\n",
        "Others stategies (median, mode) were tested but did not yield significant enhancements in performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z_dhpWnwptI"
      },
      "source": [
        "Split dataframes into 2 (one with numerical cols, one with categorical cols):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H7I1KKvwptI"
      },
      "outputs": [],
      "source": [
        "numeric_cols = data.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_cols1 = test_data.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "data_num = data[numeric_cols]\n",
        "#further separation so that the numerical columns in data and test_data are the same\n",
        "data_num1 = data_num[[\"LOS\", \"HOSPITAL_EXPIRE_FLAG\"]]\n",
        "data_num2 = data_num.drop([\"LOS\", \"HOSPITAL_EXPIRE_FLAG\"], axis =1)\n",
        "\n",
        "data_cat = data.drop(numeric_cols, axis=1)\n",
        "\n",
        "\n",
        "test_data_num = test_data[numeric_cols1]\n",
        "\n",
        "test_data_cat = test_data.drop(numeric_cols1, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Edee1GzEwptJ"
      },
      "outputs": [],
      "source": [
        "#we store the name of the columns:\n",
        "\n",
        "data_num1_colnames = data_num1.columns\n",
        "data_num2_colnames = data_num2.columns\n",
        "test_data_num_colnames = test_data_num.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtJHlaIwptJ"
      },
      "source": [
        "Import, train and apply SimpleImputer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0osz5DzFwptJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "imp_mean.fit(data_num2)\n",
        "\n",
        "data_num2 = pd.DataFrame(imp_mean.transform(data_num2)) \n",
        "test_data_num = pd.DataFrame(imp_mean.transform(test_data_num))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wpvf_8SFwptJ"
      },
      "source": [
        "Note how we apply the same fitted imputer -with df.data- to data and test_data.\n",
        "\n",
        "We reassign names to the columns:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "OycTkpxAwptJ",
        "outputId": "0d9df320-554c-4fca-d142-639c0380680e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>HeartRate_Min</th>\n",
              "      <th>HeartRate_Max</th>\n",
              "      <th>HeartRate_Mean</th>\n",
              "      <th>SysBP_Min</th>\n",
              "      <th>SysBP_Max</th>\n",
              "      <th>SysBP_Mean</th>\n",
              "      <th>DiasBP_Min</th>\n",
              "      <th>DiasBP_Max</th>\n",
              "      <th>DiasBP_Mean</th>\n",
              "      <th>MeanBP_Min</th>\n",
              "      <th>MeanBP_Max</th>\n",
              "      <th>MeanBP_Mean</th>\n",
              "      <th>RespRate_Min</th>\n",
              "      <th>RespRate_Max</th>\n",
              "      <th>RespRate_Mean</th>\n",
              "      <th>TempC_Min</th>\n",
              "      <th>TempC_Max</th>\n",
              "      <th>TempC_Mean</th>\n",
              "      <th>SpO2_Min</th>\n",
              "      <th>SpO2_Max</th>\n",
              "      <th>SpO2_Mean</th>\n",
              "      <th>Glucose_Min</th>\n",
              "      <th>Glucose_Max</th>\n",
              "      <th>Glucose_Mean</th>\n",
              "      <th>LOS</th>\n",
              "      <th>Age</th>\n",
              "      <th>ADM_year</th>\n",
              "      <th>ADM_month</th>\n",
              "      <th>ADM_weekday</th>\n",
              "      <th>ADM_hour</th>\n",
              "      <th>repeat</th>\n",
              "      <th>SEQ_NUM</th>\n",
              "      <th>51881</th>\n",
              "      <th>4019</th>\n",
              "      <th>42731</th>\n",
              "      <th>5849</th>\n",
              "      <th>99592</th>\n",
              "      <th>4280</th>\n",
              "      <th>...</th>\n",
              "      <th>99592+5845</th>\n",
              "      <th>5849+40390</th>\n",
              "      <th>4280+78552</th>\n",
              "      <th>4019+41401</th>\n",
              "      <th>5849+2724</th>\n",
              "      <th>4280+486</th>\n",
              "      <th>5849+5990</th>\n",
              "      <th>4280+5859</th>\n",
              "      <th>51881+2875</th>\n",
              "      <th>99592+486</th>\n",
              "      <th>42731+486</th>\n",
              "      <th>5849+V4986</th>\n",
              "      <th>5849+5859</th>\n",
              "      <th>5849+41401</th>\n",
              "      <th>2762+5845</th>\n",
              "      <th>51881+4275</th>\n",
              "      <th>42731+40390</th>\n",
              "      <th>4019+78552</th>\n",
              "      <th>V4986+2724</th>\n",
              "      <th>42731+5990</th>\n",
              "      <th>99592+25000</th>\n",
              "      <th>2724+25000</th>\n",
              "      <th>4280+V4986</th>\n",
              "      <th>5849+V667</th>\n",
              "      <th>0389+486</th>\n",
              "      <th>99592+2875</th>\n",
              "      <th>2724+41401</th>\n",
              "      <th>4019+486</th>\n",
              "      <th>51881+40390</th>\n",
              "      <th>4280+V5861</th>\n",
              "      <th>51881+2760</th>\n",
              "      <th>42731+V667</th>\n",
              "      <th>5849+2875</th>\n",
              "      <th>51881+2761</th>\n",
              "      <th>99592+5990</th>\n",
              "      <th>78552+5845</th>\n",
              "      <th>42731+5859</th>\n",
              "      <th>42731+5845</th>\n",
              "      <th>2762+25000</th>\n",
              "      <th>51881+496</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>195768</td>\n",
              "      <td>89.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>121.043478</td>\n",
              "      <td>74.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>106.586957</td>\n",
              "      <td>42.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>61.173913</td>\n",
              "      <td>59.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>74.543478</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.347826</td>\n",
              "      <td>35.111111</td>\n",
              "      <td>36.944444</td>\n",
              "      <td>36.080247</td>\n",
              "      <td>90.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>95.739130</td>\n",
              "      <td>111.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>160.777778</td>\n",
              "      <td>4.5761</td>\n",
              "      <td>69.557495</td>\n",
              "      <td>2008</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>126136</td>\n",
              "      <td>63.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>79.117647</td>\n",
              "      <td>89.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>106.733333</td>\n",
              "      <td>49.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>64.733333</td>\n",
              "      <td>58.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>74.800000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>16.058824</td>\n",
              "      <td>36.333333</td>\n",
              "      <td>36.611111</td>\n",
              "      <td>36.472222</td>\n",
              "      <td>98.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.058824</td>\n",
              "      <td>103.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.7582</td>\n",
              "      <td>42.073922</td>\n",
              "      <td>2010</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  234 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   HOSPITAL_EXPIRE_FLAG  HADM_ID  ...  2762+25000  51881+496\n",
              "0                     0   195768  ...           0          0\n",
              "1                     0   126136  ...           0          0\n",
              "\n",
              "[2 rows x 234 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_num1.columns = data_num1_colnames\n",
        "data_num2.columns = data_num2_colnames\n",
        "test_data_num.columns = test_data_num_colnames\n",
        "data_num.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBJqEbLbwptJ"
      },
      "source": [
        "Now we rejoin each dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPBx8JwCwptJ"
      },
      "outputs": [],
      "source": [
        "data_num = pd.concat([data_num1, data_num2], axis=1, join=\"inner\")\n",
        "data = pd.concat([data_cat, data_num], axis=1, join=\"inner\")\n",
        "test_data = pd.concat([test_data_cat, test_data_num], axis=1, join=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "c2KgPVXmwptJ",
        "outputId": "cbd39af9-92c6-49bb-ee94-9d78d381b3e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GENDER</th>\n",
              "      <th>ADMISSION_TYPE</th>\n",
              "      <th>INSURANCE</th>\n",
              "      <th>RELIGION</th>\n",
              "      <th>MARITAL_STATUS</th>\n",
              "      <th>ETHNICITY</th>\n",
              "      <th>FIRST_CAREUNIT</th>\n",
              "      <th>ADM_season</th>\n",
              "      <th>LOS</th>\n",
              "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>HeartRate_Min</th>\n",
              "      <th>HeartRate_Max</th>\n",
              "      <th>HeartRate_Mean</th>\n",
              "      <th>SysBP_Min</th>\n",
              "      <th>SysBP_Max</th>\n",
              "      <th>SysBP_Mean</th>\n",
              "      <th>DiasBP_Min</th>\n",
              "      <th>DiasBP_Max</th>\n",
              "      <th>DiasBP_Mean</th>\n",
              "      <th>MeanBP_Min</th>\n",
              "      <th>MeanBP_Max</th>\n",
              "      <th>MeanBP_Mean</th>\n",
              "      <th>RespRate_Min</th>\n",
              "      <th>RespRate_Max</th>\n",
              "      <th>RespRate_Mean</th>\n",
              "      <th>TempC_Min</th>\n",
              "      <th>TempC_Max</th>\n",
              "      <th>TempC_Mean</th>\n",
              "      <th>SpO2_Min</th>\n",
              "      <th>SpO2_Max</th>\n",
              "      <th>SpO2_Mean</th>\n",
              "      <th>Glucose_Min</th>\n",
              "      <th>Glucose_Max</th>\n",
              "      <th>Glucose_Mean</th>\n",
              "      <th>Age</th>\n",
              "      <th>ADM_year</th>\n",
              "      <th>ADM_month</th>\n",
              "      <th>ADM_weekday</th>\n",
              "      <th>ADM_hour</th>\n",
              "      <th>...</th>\n",
              "      <th>99592+5845</th>\n",
              "      <th>5849+40390</th>\n",
              "      <th>4280+78552</th>\n",
              "      <th>4019+41401</th>\n",
              "      <th>5849+2724</th>\n",
              "      <th>4280+486</th>\n",
              "      <th>5849+5990</th>\n",
              "      <th>4280+5859</th>\n",
              "      <th>51881+2875</th>\n",
              "      <th>99592+486</th>\n",
              "      <th>42731+486</th>\n",
              "      <th>5849+V4986</th>\n",
              "      <th>5849+5859</th>\n",
              "      <th>5849+41401</th>\n",
              "      <th>2762+5845</th>\n",
              "      <th>51881+4275</th>\n",
              "      <th>42731+40390</th>\n",
              "      <th>4019+78552</th>\n",
              "      <th>V4986+2724</th>\n",
              "      <th>42731+5990</th>\n",
              "      <th>99592+25000</th>\n",
              "      <th>2724+25000</th>\n",
              "      <th>4280+V4986</th>\n",
              "      <th>5849+V667</th>\n",
              "      <th>0389+486</th>\n",
              "      <th>99592+2875</th>\n",
              "      <th>2724+41401</th>\n",
              "      <th>4019+486</th>\n",
              "      <th>51881+40390</th>\n",
              "      <th>4280+V5861</th>\n",
              "      <th>51881+2760</th>\n",
              "      <th>42731+V667</th>\n",
              "      <th>5849+2875</th>\n",
              "      <th>51881+2761</th>\n",
              "      <th>99592+5990</th>\n",
              "      <th>78552+5845</th>\n",
              "      <th>42731+5859</th>\n",
              "      <th>42731+5845</th>\n",
              "      <th>2762+25000</th>\n",
              "      <th>51881+496</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F</td>\n",
              "      <td>EMERGENCY</td>\n",
              "      <td>Medicare</td>\n",
              "      <td>PROTESTANT QUAKER</td>\n",
              "      <td>SINGLE</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>MICU</td>\n",
              "      <td>Spring</td>\n",
              "      <td>4.5761</td>\n",
              "      <td>0</td>\n",
              "      <td>195768.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>121.043478</td>\n",
              "      <td>74.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>106.586957</td>\n",
              "      <td>42.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>61.173913</td>\n",
              "      <td>59.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>74.543478</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.347826</td>\n",
              "      <td>35.111111</td>\n",
              "      <td>36.944444</td>\n",
              "      <td>36.080247</td>\n",
              "      <td>90.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>95.739130</td>\n",
              "      <td>111.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>160.777778</td>\n",
              "      <td>69.557495</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>EMERGENCY</td>\n",
              "      <td>Private</td>\n",
              "      <td>UNOBTAINABLE</td>\n",
              "      <td>MARRIED</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>MICU</td>\n",
              "      <td>Autumn</td>\n",
              "      <td>0.7582</td>\n",
              "      <td>0</td>\n",
              "      <td>126136.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>79.117647</td>\n",
              "      <td>89.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>106.733333</td>\n",
              "      <td>49.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>64.733333</td>\n",
              "      <td>58.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>74.800000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>16.058824</td>\n",
              "      <td>36.333333</td>\n",
              "      <td>36.611111</td>\n",
              "      <td>36.472222</td>\n",
              "      <td>98.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.058824</td>\n",
              "      <td>103.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>42.073922</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  242 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  GENDER ADMISSION_TYPE INSURANCE  ... 42731+5845 2762+25000 51881+496\n",
              "0      F      EMERGENCY  Medicare  ...        0.0        0.0       0.0\n",
              "1      F      EMERGENCY   Private  ...        0.0        0.0       0.0\n",
              "\n",
              "[2 rows x 242 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WsdzMRNwptJ",
        "outputId": "16fbc482-fd12-4dc6-c032-4c2a892023ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "722\n"
          ]
        }
      ],
      "source": [
        "#check for nulls:\n",
        "Nulls = sum(data.isnull().sum())\n",
        "print(Nulls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jXQGHrcwptK"
      },
      "source": [
        "Dealing with Marital Status' NAs:\n",
        "\n",
        "We reclassify NAs as the category \"UNKNOWN (DEFAULT)\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yoq8dzmgwptK",
        "outputId": "1f114d33-a792-469d-912b-28f0b0b415ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['SINGLE', 'MARRIED', 'SEPARATED', 'WIDOWED', 'DIVORCED', nan,\n",
              "       'UNKNOWN (DEFAULT)', 'LIFE PARTNER'], dtype=object)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['MARITAL_STATUS'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7-kI5U-wptK",
        "outputId": "20951fb4-9e4d-417c-8640-c4844d49bcf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['SINGLE', 'MARRIED', 'SEPARATED', 'WIDOWED', 'DIVORCED',\n",
              "       'UNKNOWN (DEFAULT)', 'LIFE PARTNER'], dtype=object)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.MARITAL_STATUS.fillna('UNKNOWN (DEFAULT)', inplace=True)\n",
        "data['MARITAL_STATUS'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LACKHAITwptK"
      },
      "source": [
        "We check if there are any more NAs in the \"data\" dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvF22p-SwptK",
        "outputId": "d3f03e6e-e6ba-4758-9c8d-846909a696b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "Nulls = data.isnull().sum()\n",
        "print(sum(Nulls))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWdqBwJKwptK"
      },
      "source": [
        "Solving the NA problem for the test_data. This is the same process as above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gXEF8TvwptK",
        "outputId": "c6a263a3-976f-4891-9ea5-32f91a640523"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['MARRIED', 'WIDOWED', 'SINGLE', 'DIVORCED', 'UNKNOWN (DEFAULT)',\n",
              "       'SEPARATED', 'LIFE PARTNER'], dtype=object)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.MARITAL_STATUS.fillna('UNKNOWN (DEFAULT)', inplace=True)\n",
        "test_data['MARITAL_STATUS'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd_SRU7PwptK",
        "outputId": "348cdb6c-35a7-4c86-bf19-5ae8514c07b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check it worked:\n",
        "sum(test_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LFLsn-BwptK"
      },
      "source": [
        "##Dealing with categorical features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e78lGGx2wptK"
      },
      "source": [
        "We analyze the nature of the following categorical features:\n",
        "- GENDER\n",
        "- ADMISSION_TYPE\n",
        "- INSURANCE\n",
        "- RELIGION\n",
        "- MARITAL STATUS\n",
        "- ETHNICITY\n",
        "- DIAGNOSIS\n",
        "- FIRST_CAREUNIT\n",
        "\n",
        "We check if few categories gather most of the cases, if they are binary or multiclass, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoSLDctXwptK",
        "outputId": "67e5fc5b-1690-442a-85eb-49e5e92cc7ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['F' 'M']\n",
            "['EMERGENCY' 'ELECTIVE' 'URGENT']\n",
            "['Medicare' 'Private' 'Medicaid' 'Self Pay' 'Government']\n",
            "['PROTESTANT QUAKER' 'UNOBTAINABLE' 'NOT SPECIFIED' 'JEWISH' 'CATHOLIC'\n",
            " 'OTHER' 'BUDDHIST' 'EPISCOPALIAN' 'ROMANIAN EAST. ORTH' 'GREEK ORTHODOX'\n",
            " \"JEHOVAH'S WITNESS\" 'MUSLIM' 'CHRISTIAN SCIENTIST' 'HINDU'\n",
            " '7TH DAY ADVENTIST' 'UNITARIAN-UNIVERSALIST' 'HEBREW']\n",
            "['SINGLE' 'MARRIED' 'SEPARATED' 'WIDOWED' 'DIVORCED' 'UNKNOWN (DEFAULT)'\n",
            " 'LIFE PARTNER']\n",
            "['WHITE' 'BLACK/AFRICAN AMERICAN' 'BLACK/CAPE VERDEAN'\n",
            " 'UNKNOWN/NOT SPECIFIED' 'PATIENT DECLINED TO ANSWER'\n",
            " 'ASIAN - ASIAN INDIAN' 'OTHER' 'HISPANIC/LATINO - PUERTO RICAN' 'ASIAN'\n",
            " 'HISPANIC OR LATINO' 'UNABLE TO OBTAIN' 'BLACK/HAITIAN'\n",
            " 'WHITE - OTHER EUROPEAN' 'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER'\n",
            " 'WHITE - RUSSIAN' 'WHITE - EASTERN EUROPEAN' 'ASIAN - CHINESE'\n",
            " 'HISPANIC/LATINO - CUBAN' 'ASIAN - VIETNAMESE' 'MULTI RACE ETHNICITY'\n",
            " 'AMERICAN INDIAN/ALASKA NATIVE' 'MIDDLE EASTERN' 'ASIAN - KOREAN'\n",
            " 'CARIBBEAN ISLAND' 'PORTUGUESE' 'HISPANIC/LATINO - SALVADORAN'\n",
            " 'ASIAN - FILIPINO' 'HISPANIC/LATINO - GUATEMALAN' 'ASIAN - CAMBODIAN'\n",
            " 'HISPANIC/LATINO - DOMINICAN' 'WHITE - BRAZILIAN'\n",
            " 'HISPANIC/LATINO - CENTRAL AMERICAN (OTHER)' 'HISPANIC/LATINO - HONDURAN'\n",
            " 'HISPANIC/LATINO - MEXICAN' 'BLACK/AFRICAN' 'ASIAN - JAPANESE'\n",
            " 'HISPANIC/LATINO - COLOMBIAN'\n",
            " 'AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE'\n",
            " 'ASIAN - OTHER' 'SOUTH AMERICAN' 'ASIAN - THAI']\n",
            "['MICU' 'SICU' 'TSICU' 'CSRU' 'CCU']\n"
          ]
        }
      ],
      "source": [
        "list = ['GENDER', 'ADMISSION_TYPE','INSURANCE', 'RELIGION','MARITAL_STATUS',\n",
        "                        'ETHNICITY', 'FIRST_CAREUNIT']\n",
        "for i in list:\n",
        "  print(data[i].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3f0nWbMwptK"
      },
      "source": [
        "Many plots like the following were used to see how to deal with multiclass variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "26nhBnQPwptL",
        "outputId": "cb7a99c3-1f0d-478d-bd12-9b5e526d7330"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e9f796950>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "data.ETHNICITY.value_counts().plot(kind=\"bar\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHd5G-dwptL"
      },
      "source": [
        "For instance, it seems like a good idea to bundle some of the classes in the \"Ethnicity\" feature as \"Other\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSWp5lHXwptL"
      },
      "source": [
        "Through the previous analysis, we classify the features as:\n",
        "\n",
        "- Binary: just get dummy.\n",
        "    - GENDER\n",
        "- Multiclass, with all classes present. Get dummies. \n",
        "    - ADMISSION_TYPE\n",
        "    - INSURANCE\n",
        "    - MARITAL STATUS\n",
        "    - FIRST_CAREUNIT\n",
        "    - SEASON\n",
        "    - YEAR\n",
        "    - WEEKDAY\n",
        "    - HOUR\n",
        "- Multiclass, with some classes that can be bundled together under \"Other\":\n",
        "    - RELIGION\n",
        "    - ETHNICITY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVtKNYfNfQqK"
      },
      "outputs": [],
      "source": [
        "data = data.drop([\"ADM_month\"], axis=1)\n",
        "data = pd.get_dummies(data, prefix=['Season'], columns=['ADM_season'], drop_first = True)\n",
        "data = pd.get_dummies(data, prefix=['y'], columns=['ADM_year'], drop_first = True)\n",
        "data = pd.get_dummies(data, prefix=['wd'], columns=['ADM_weekday'], drop_first = True)\n",
        "data = pd.get_dummies(data, prefix=['h'], columns=['ADM_hour'], drop_first = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL6UFF7ogdHT"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.drop([\"ADM_month\"], axis=1)\n",
        "test_data = pd.get_dummies(test_data, prefix=['Season'], columns=['ADM_season'], drop_first = True)\n",
        "test_data = pd.get_dummies(test_data, prefix=['y'], columns=['ADM_year'], drop_first = True)\n",
        "test_data = pd.get_dummies(test_data, prefix=['wd'], columns=['ADM_weekday'], drop_first = True)\n",
        "test_data = pd.get_dummies(test_data, prefix=['h'], columns=['ADM_hour'], drop_first = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYvhihgfwptL"
      },
      "outputs": [],
      "source": [
        "# for the data:\n",
        "data = pd.get_dummies(data = data, columns=['GENDER'], drop_first = True)\n",
        "\n",
        "data = pd.get_dummies(data, prefix=['ADM_TYPE'], columns=['ADMISSION_TYPE'], drop_first = True)\n",
        "\n",
        "eth_list = []\n",
        "for j in data['ETHNICITY']:\n",
        "  if j == \"WHITE\":\n",
        "    eth_list.append(\"WHITE\")\n",
        "  elif j == \"BLACK/AFRICAN AMERICAN\":\n",
        "    eth_list.append(\"BLACK/AFRICAN AMERICAN\")\n",
        "  else:\n",
        "    eth_list.append(\"OTHER\")\n",
        "data = data.drop([\"ETHNICITY\"], axis=1)\n",
        "data[\"ETHNICITY\"] = eth_list\n",
        "data = pd.get_dummies(data, prefix=['ETH'], columns=['ETHNICITY'], drop_first = True)\n",
        "\n",
        "data = pd.get_dummies(data, prefix=['MARITAL'], columns=['MARITAL_STATUS'], drop_first = True)\n",
        "\n",
        "rel = []\n",
        "for k in data['RELIGION']:\n",
        "  if k == \"CATHOLIC\":\n",
        "    rel.append(\"CATHOLIC\")\n",
        "  elif k == \"PROTESTANT QUAKER\":\n",
        "    rel.append(\"PROTESTANT QUAKER\")\n",
        "  elif k == \"JEWISH\":\n",
        "    rel.append(\"JEWISH\")\n",
        "  else:\n",
        "    rel.append(\"OTHER\")\n",
        "data = data.drop([\"RELIGION\"], axis=1)\n",
        "data[\"RELIGION\"] = rel\n",
        "data = pd.get_dummies(data, prefix=['REL'], columns=['RELIGION'], drop_first = True)\n",
        "\n",
        "data = pd.get_dummies(data, prefix=['INS'], columns=['INSURANCE'], drop_first = True)\n",
        "\n",
        "data = pd.get_dummies(data, prefix=['CAREUNIT'], columns=['FIRST_CAREUNIT'], drop_first = True)\n",
        "\n",
        "#data = data.drop([\"DIAGNOSIS\"], axis=1)\n",
        "#data = data.drop([\"ICD9_CODE\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3vI446CwptL"
      },
      "outputs": [],
      "source": [
        "# for the test_data\n",
        "test_data = pd.get_dummies(data = test_data, columns=['GENDER'], drop_first = True)\n",
        "\n",
        "test_data = pd.get_dummies(test_data, prefix=['ADM_TYPE'], columns=['ADMISSION_TYPE'], drop_first = True)\n",
        "\n",
        "eth_list = []\n",
        "for j in test_data['ETHNICITY']:\n",
        "  if j == \"WHITE\":\n",
        "    eth_list.append(\"WHITE\")\n",
        "  elif j == \"BLACK/AFRICAN AMERICAN\":\n",
        "    eth_list.append(\"BLACK/AFRICAN AMERICAN\")\n",
        "  else:\n",
        "    eth_list.append(\"OTHER\")\n",
        "test_data = test_data.drop([\"ETHNICITY\"], axis=1)\n",
        "test_data[\"ETHNICITY\"] = eth_list\n",
        "test_data = pd.get_dummies(test_data, prefix=['ETH'], columns=['ETHNICITY'], drop_first = True)\n",
        "\n",
        "test_data = pd.get_dummies(test_data, prefix=['MARITAL'], columns=['MARITAL_STATUS'], drop_first = True)\n",
        "\n",
        "rel = []\n",
        "for k in test_data['RELIGION']:\n",
        "  if k == \"CATHOLIC\":\n",
        "    rel.append(\"CATHOLIC\")\n",
        "  elif k == \"PROTESTANT QUAKER\":\n",
        "    rel.append(\"PROTESTANT QUAKER\")\n",
        "  elif k == \"JEWISH\":\n",
        "    rel.append(\"JEWISH\")\n",
        "  else:\n",
        "    rel.append(\"OTHER\")\n",
        "test_data = test_data.drop([\"RELIGION\"], axis=1)\n",
        "test_data[\"RELIGION\"] = rel\n",
        "test_data = pd.get_dummies(test_data, prefix=['REL'], columns=['RELIGION'], drop_first = True)\n",
        "\n",
        "test_data = pd.get_dummies(test_data, prefix=['INS'], columns=['INSURANCE'], drop_first = True)\n",
        "\n",
        "test_data = pd.get_dummies(test_data, prefix=['CAREUNIT'], columns=['FIRST_CAREUNIT'], drop_first = True)\n",
        "\n",
        "#test_data = test_data.drop([\"DIAGNOSIS\"], axis=1)\n",
        "#test_data = test_data.drop([\"ICD9_CODE\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oADgvHdOwptL"
      },
      "source": [
        "We check final dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7yTO7mdwptL",
        "outputId": "a09b796d-0950-48c1-dfd2-3f8f6215040f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20885, 289)\n",
            "(5221, 287)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "hFCu0PBaPgP_",
        "outputId": "82cc06a6-1de9-4879-8aaf-d98a22696492"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LOS</th>\n",
              "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>HeartRate_Min</th>\n",
              "      <th>HeartRate_Max</th>\n",
              "      <th>HeartRate_Mean</th>\n",
              "      <th>SysBP_Min</th>\n",
              "      <th>SysBP_Max</th>\n",
              "      <th>SysBP_Mean</th>\n",
              "      <th>DiasBP_Min</th>\n",
              "      <th>DiasBP_Max</th>\n",
              "      <th>DiasBP_Mean</th>\n",
              "      <th>MeanBP_Min</th>\n",
              "      <th>MeanBP_Max</th>\n",
              "      <th>MeanBP_Mean</th>\n",
              "      <th>RespRate_Min</th>\n",
              "      <th>RespRate_Max</th>\n",
              "      <th>RespRate_Mean</th>\n",
              "      <th>TempC_Min</th>\n",
              "      <th>TempC_Max</th>\n",
              "      <th>TempC_Mean</th>\n",
              "      <th>SpO2_Min</th>\n",
              "      <th>SpO2_Max</th>\n",
              "      <th>SpO2_Mean</th>\n",
              "      <th>Glucose_Min</th>\n",
              "      <th>Glucose_Max</th>\n",
              "      <th>Glucose_Mean</th>\n",
              "      <th>Age</th>\n",
              "      <th>repeat</th>\n",
              "      <th>SEQ_NUM</th>\n",
              "      <th>51881</th>\n",
              "      <th>4019</th>\n",
              "      <th>42731</th>\n",
              "      <th>5849</th>\n",
              "      <th>99592</th>\n",
              "      <th>4280</th>\n",
              "      <th>2762</th>\n",
              "      <th>0389</th>\n",
              "      <th>V4986</th>\n",
              "      <th>78552</th>\n",
              "      <th>...</th>\n",
              "      <th>h_6.0</th>\n",
              "      <th>h_7.0</th>\n",
              "      <th>h_8.0</th>\n",
              "      <th>h_9.0</th>\n",
              "      <th>h_10.0</th>\n",
              "      <th>h_11.0</th>\n",
              "      <th>h_12.0</th>\n",
              "      <th>h_13.0</th>\n",
              "      <th>h_14.0</th>\n",
              "      <th>h_15.0</th>\n",
              "      <th>h_16.0</th>\n",
              "      <th>h_17.0</th>\n",
              "      <th>h_18.0</th>\n",
              "      <th>h_19.0</th>\n",
              "      <th>h_20.0</th>\n",
              "      <th>h_21.0</th>\n",
              "      <th>h_22.0</th>\n",
              "      <th>h_23.0</th>\n",
              "      <th>GENDER_M</th>\n",
              "      <th>ADM_TYPE_EMERGENCY</th>\n",
              "      <th>ADM_TYPE_URGENT</th>\n",
              "      <th>ETH_OTHER</th>\n",
              "      <th>ETH_WHITE</th>\n",
              "      <th>MARITAL_LIFE PARTNER</th>\n",
              "      <th>MARITAL_MARRIED</th>\n",
              "      <th>MARITAL_SEPARATED</th>\n",
              "      <th>MARITAL_SINGLE</th>\n",
              "      <th>MARITAL_UNKNOWN (DEFAULT)</th>\n",
              "      <th>MARITAL_WIDOWED</th>\n",
              "      <th>REL_JEWISH</th>\n",
              "      <th>REL_OTHER</th>\n",
              "      <th>REL_PROTESTANT QUAKER</th>\n",
              "      <th>INS_Medicaid</th>\n",
              "      <th>INS_Medicare</th>\n",
              "      <th>INS_Private</th>\n",
              "      <th>INS_Self Pay</th>\n",
              "      <th>CAREUNIT_CSRU</th>\n",
              "      <th>CAREUNIT_MICU</th>\n",
              "      <th>CAREUNIT_SICU</th>\n",
              "      <th>CAREUNIT_TSICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.5761</td>\n",
              "      <td>0</td>\n",
              "      <td>195768.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>121.043478</td>\n",
              "      <td>74.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>106.586957</td>\n",
              "      <td>42.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>61.173913</td>\n",
              "      <td>59.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>74.543478</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>22.347826</td>\n",
              "      <td>35.111111</td>\n",
              "      <td>36.944444</td>\n",
              "      <td>36.080247</td>\n",
              "      <td>90.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>95.739130</td>\n",
              "      <td>111.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>160.777778</td>\n",
              "      <td>69.557495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.7582</td>\n",
              "      <td>0</td>\n",
              "      <td>126136.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>79.117647</td>\n",
              "      <td>89.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>106.733333</td>\n",
              "      <td>49.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>64.733333</td>\n",
              "      <td>58.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>74.800000</td>\n",
              "      <td>13.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>16.058824</td>\n",
              "      <td>36.333333</td>\n",
              "      <td>36.611111</td>\n",
              "      <td>36.472222</td>\n",
              "      <td>98.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>99.058824</td>\n",
              "      <td>103.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>42.073922</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows  289 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      LOS  HOSPITAL_EXPIRE_FLAG  ...  CAREUNIT_SICU  CAREUNIT_TSICU\n",
              "0  4.5761                     0  ...              0               0\n",
              "1  0.7582                     0  ...              0               0\n",
              "\n",
              "[2 rows x 289 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH4XMTblwptL"
      },
      "source": [
        "##Save to csv, for faster code runs in the future:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwIaGw-XwptL"
      },
      "outputs": [],
      "source": [
        "data.to_csv(path_or_buf='data.csv', index=False)\n",
        "test_data.to_csv(path_or_buf='test_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4k0Bw8kwptQ"
      },
      "source": [
        "<a name=\"models\"></a>\n",
        "#<font color='blue'> Models!</font> \n",
        "<font color='red'>*You can quickly load the output of the previous sections here*</font>\n",
        "\n",
        "In this section we fit our models, check accuracy and generate predictions.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBBtjfzC4XeM"
      },
      "source": [
        "Two main predictions were made:\n",
        "\n",
        "1. Death predictions: we used the HOSPITAL_EXPIRE_FLAG data in our training set to predict if patients in our test set would die. <font color='green'>Classification problem</font>.\n",
        "\n",
        "2. LOS predictions: we used the previous predictions -and all the other pertinent features- to predict lengths of stay. <font color='green'>Regression problem</font>.\n",
        "\n",
        "Many features are shared by both cases, but **most of them are specific to what we want to predict**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9X7bTyJGx9-"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "We use the following models:\n",
        "\n",
        "- Random Forest Classifier.\n",
        "- Balanced Random Forest Classifier.\n",
        "- Stacking:\n",
        "  - Weak learners:\n",
        "    - KNN.\n",
        "    - LinearSVR.\n",
        "    - Random Forest Regressor.\n",
        "  - Meta learner: Extra Trees Regressor\n",
        "- XGBoosting.\n",
        "- Bagged XGBoosters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAo43LDwn4oC",
        "outputId": "b1ab2487-bd9b-4dba-ddc2-ec910778a622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#fast data loading:\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/CM1_CM2_learning/CML_materials/ensembles/kaggle')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "test_data = pd.read_csv(\"test_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQgua29M97tt"
      },
      "source": [
        "## 1. Death prediction:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KqCi9leAh96"
      },
      "source": [
        "As we saw in our Quick Analysis section - and as common sense indicates - patients who die disrupt their stay so estimating if a patient will die is a good feature for LOS regressing.\n",
        "\n",
        "We will try a few bagged classifiers to predict the probability of death of patients and add that information to our datasets.\n",
        "\n",
        "Note we do not use the LOS column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbxj7KbI-xHR"
      },
      "source": [
        "###Prepping the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aklvVICwptQ",
        "outputId": "2b0a60cf-9843-4588-e94e-f7dba93e23d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20885, 286)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(5221, 286)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = data.drop([\"HOSPITAL_EXPIRE_FLAG\", \"LOS\", \"HADM_ID\"], axis =1)\n",
        "y = data[\"HOSPITAL_EXPIRE_FLAG\"]\n",
        "X_test = test_data.drop([\"HADM_ID\"], axis =1)\n",
        "print(X.shape)\n",
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyLX5TOhFNZV"
      },
      "source": [
        "### Models for Classification:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly-OS9JS_IXM"
      },
      "source": [
        "Trying a Random Forest Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJk588WhCXXn",
        "outputId": "778683f9-f1a8-41f0-c57e-671cfb369790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean ROC AUC: 0.930 (+/- 0.009)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators = 150, \n",
        "                                criterion = \"entropy\",\n",
        "                                max_features = \"sqrt\",\n",
        "                                n_jobs = 8,\n",
        "                                verbose = 0,\n",
        "                                class_weight = \"balanced_subsample\") #for class imbalance\n",
        "\n",
        "#Grid Search performed to determine above hyperparameters:\n",
        "\n",
        "#parameters = {'n_estimators': [150],\n",
        "              #'criterion':[\"gini\", \"entropy\"],\n",
        "              #'max_features':[\"sqrt\", \"log2\"],\n",
        "              #'class_weight': [\"balanced\", \"balanced_subsample\"]}\n",
        "\n",
        "#best_rfc = GridSearchCV(forest, parameters, cv=3, scoring='roc_auc', n_jobs = 8, verbose=3, refit=True)\n",
        "#best_rfc.fit(X, y)\n",
        "#best_rfc.best_params_\n",
        "\n",
        "scores = cross_val_score(forest, X, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "print(\"Mean ROC AUC: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aja2dUVw_fcB"
      },
      "source": [
        "Note that the RFC's hyperparameters were grid-searched and that the area under the curve of the ROC was the score which we wanted to maximize (since it is a classification problem)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltrdILKThpzr"
      },
      "source": [
        "We also tried out another set of models (Balanced RFC), which perform random undersampling of the majority class in each bootstrap sample to deal with the class imbalance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlVJrzDSMDYh",
        "outputId": "a16b4663-b5c7-44cc-ec68-653deb796308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean ROC AUC: 0.922 (+/- 0.008)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier \n",
        "model = BalancedRandomForestClassifier(n_estimators = 200,\n",
        "                                        criterion = \"entropy\",\n",
        "                                        max_features = \"sqrt\",\n",
        "                                        n_jobs = 8,\n",
        "                                        verbose = 0)\n",
        "\n",
        "#Grid Search performed to determine above hyperparameters:\n",
        "\n",
        "#parameters = {'n_estimators': [50, 100, 150, 200],\n",
        "              #'criterion':[\"gini\", \"entropy\"],\n",
        "              #'max_features':[\"sqrt\", \"log2\"]}\n",
        "\n",
        "#best_model = GridSearchCV(model, parameters, cv=5, scoring='roc_auc', n_jobs = 8, verbose=3, refit=True)\n",
        "#best_model.fit(X, y)\n",
        "#best_model.best_params_\n",
        "\n",
        "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "\n",
        "print(\"Mean ROC AUC: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpl357ovEmqQ"
      },
      "source": [
        "Again, the hyperparameters were grid-searched and the accuracy measured with a mean ROC AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcei6luKFSGK"
      },
      "source": [
        "### Prediction of death:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t36NRAmBiSZJ"
      },
      "source": [
        "We will use the Random Forest Classifier since it appears to perform slightly better:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPzMwCLJiee-"
      },
      "outputs": [],
      "source": [
        "forest.fit(X,y)\n",
        "prob_death = pd.DataFrame(forest.predict_proba(X_test), columns=['Column1', \"HOSPITAL_EXPIRE_FLAG\"]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zHWfbEYbjeX5",
        "outputId": "22a598e0-6065-452a-dadb-b5838de2b257"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Column1  HOSPITAL_EXPIRE_FLAG\n",
              "0  0.980000              0.020000\n",
              "1  0.833333              0.166667"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#to see how it looks:\n",
        "prob_death.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfH1ZgfqFezb"
      },
      "source": [
        "##2. LOS prediction:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z1lu3rBFxs8"
      },
      "source": [
        "### Prepping the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAZbHth1J6HU"
      },
      "source": [
        "<font color='red'>*You can skip this section and directly load the prepared data*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH0vn_s4nym9"
      },
      "source": [
        "We add our freshly baked probability of death feature to our test set and redefine X and y:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HwFsKvMlwg1"
      },
      "outputs": [],
      "source": [
        "X = data.drop([\"LOS\"], axis =1)\n",
        "y = data[\"LOS\"]\n",
        "X_test = pd.concat([prob_death[\"HOSPITAL_EXPIRE_FLAG\"], test_data], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YvB1DutrRDu"
      },
      "source": [
        "We drop all the features that made sense for predicting death, and replace them with the ones that make sense for predicting LOS:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp6aRl_2NpSt",
        "outputId": "9002460c-2d76-4d18-b1b5-631290043c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial X:  (20885, 288)\n",
            "initial X_test:  (5221, 288)\n",
            "X after dropping:  (20885, 88)\n",
            "X_test after dropping:  (5221, 88)\n"
          ]
        }
      ],
      "source": [
        "#dropping features for death:\n",
        "print(\"initial X: \", X.shape)\n",
        "print(\"initial X_test: \", X_test.shape)\n",
        "\n",
        "droppable = X.iloc[:, 29:229].columns\n",
        "\n",
        "#this drops the top 100 single comorbidities present in patients who die and \n",
        "#the top 100 pairwise combinations of comorbidities present in patients who die:\n",
        "X = X.drop(droppable, axis=1) \n",
        "\n",
        "#this does the same for the testset:\n",
        "X_test = X_test.drop(droppable, axis=1)\n",
        "\n",
        "\n",
        "print(\"X after dropping: \", X.shape)\n",
        "print(\"X_test after dropping: \", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p76Lq4SXjX2",
        "outputId": "b9b45d2a-704f-40c2-c017-b6faa8f46bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X after adding:  (20885, 238)\n",
            "X_test after adding:  (5221, 238)\n"
          ]
        }
      ],
      "source": [
        "#adding features for LOS:\n",
        "top_comorbs_stay.append(\"HADM_ID\")\n",
        "de2 = de[top_comorbs_stay]\n",
        "\n",
        "#this adds the top 150 comorbidities that are distinctly more likely to be present in short and long stay patients: \n",
        "X = X.merge(de2, on='HADM_ID', how='left')\n",
        "X_test = X_test.merge(de2, on='HADM_ID', how='left')\n",
        "\n",
        "print(\"X after adding: \", X.shape)\n",
        "print(\"X_test after adding: \", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY65Jz-lX9aW"
      },
      "outputs": [],
      "source": [
        "#this drops HADM_ID which has no use now:\n",
        "X = X.drop([\"HADM_ID\"], axis =1)\n",
        "X_test = X_test.drop([\"HADM_ID\"], axis =1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DygynIwrJxbp"
      },
      "source": [
        "Save the output for future runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNr1gcpyPfaP"
      },
      "outputs": [],
      "source": [
        "X.to_csv(path_or_buf='X_for_LOS.csv', index=False)\n",
        "X_test.to_csv(path_or_buf='X_test_for_LOS.csv', index=False)\n",
        "y.to_csv(path_or_buf='yfor_LOS.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOmlXTg2qTdC"
      },
      "source": [
        "### Regression Models:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UGmZCCYLPUt"
      },
      "source": [
        "<font color='red'>*Quickly load the output of the previous section*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojy1jf4-LpIw",
        "outputId": "9eee9e94-4ac8-4977-a836-42a83f42267d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20885, 237)\n",
            "(5221, 237)\n",
            "(20885, 1)\n"
          ]
        }
      ],
      "source": [
        "#quick load\n",
        "\n",
        "X = pd.read_csv('X_for_LOS.csv')\n",
        "X_test = pd.read_csv('X_test_for_LOS.csv')\n",
        "y = pd.read_csv('yfor_LOS.csv')\n",
        "for i in [X, X_test, y]:\n",
        "  print(i.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKAgFQ6EffH3"
      },
      "source": [
        "#### Stacking:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYXxPgdGfp7b"
      },
      "source": [
        "As weak learners, we used k-Nearest Neighbors, a Support Vector Machine model and a Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n9s3LUegBRW"
      },
      "source": [
        "Pre-requisites:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDU8FR8cMUxL"
      },
      "outputs": [],
      "source": [
        "# Scale inputs for kNN and SVM\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler(with_mean=True, with_std=True).fit(X)\n",
        "X = scaler.transform(X)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjD98v1CNv8s",
        "outputId": "5d9b60d7-eee2-4206-81c1-c41520523f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17752, 237)\n",
            "(3133, 237)\n",
            "(17752, 1)\n",
            "(3133, 1)\n"
          ]
        }
      ],
      "source": [
        "# Split the data in order to measure accuracy of the models, since cross-validation would take too long.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.15, random_state=123)\n",
        "\n",
        "for i in [xtrain, xtest, ytrain, ytest]:\n",
        "  print(i.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DhGCH9igKEC"
      },
      "source": [
        "1. KNN Regressor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SecqOkYkYAd4",
        "outputId": "03d12035-ecc7-453b-c984-0df00becda2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE kNN: 5.641\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=100)\n",
        "knn.fit(xtrain, ytrain)\n",
        "knnPred = knn.predict(xtest)\n",
        "score = mean_squared_error(ytest, knnPred, squared= False)\n",
        "print(\"RMSE kNN:\", \"%.3f\" % (score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2WrCK-SgP5_"
      },
      "source": [
        "2. Linear SVR:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK0JouUUY510",
        "outputId": "0386b136-d59c-4bba-ca07-7d7da79b7f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibLinear]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE SVR: 5.091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "svr = LinearSVR(C=10, verbose = 2) \n",
        "svr.fit(xtrain, ytrain)\n",
        "svrPred = svr.predict(xtest)\n",
        "score = mean_squared_error(ytest, svrPred, squared= False)\n",
        "print(\"RMSE SVR:\", \"%.3f\" % (score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w9HT7aDgUhU"
      },
      "source": [
        "3. Random Forest Regressor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6SSp7dCZb_B",
        "outputId": "386b7bfa-4b71-4f33-a74b-2fc079d46c1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE RF: 4.601\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators=50, max_features=100, random_state=10) \n",
        "rf.fit(xtrain, ytrain)\n",
        "rfPred = rf.predict(xtest)\n",
        "score = mean_squared_error(ytest, rfPred, squared= False)\n",
        "print(\"RMSE RF:\", \"%.3f\" % (score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1LkA6s7ggtB"
      },
      "source": [
        "We use an Extra Trees Regressor as the meta-learner:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WAOkTFnb7NM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "meta_learner = ExtraTreesRegressor(\n",
        "    n_estimators=50,\n",
        "    bootstrap=True,\n",
        "    max_features=0.7,\n",
        "    random_state=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b7YXk2lgopF"
      },
      "source": [
        "Actual stacking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4CgGC-XcsFi",
        "outputId": "0a606a38-366c-4433-9e80-0de972b07465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlens\n",
            "  Downloading mlens-0.2.3-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[?25l\r\u001b[K     |                              | 10 kB 21.4 MB/s eta 0:00:01\r\u001b[K     |                             | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |                           | 30 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |                          | 40 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |                        | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |                       | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |                      | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |                    | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |                   | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |                 | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |                | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |              | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |             | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |           | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |          | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |         | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |       | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |      | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |    | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |   | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     | | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     || 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     || 227 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlens) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from mlens) (1.19.5)\n",
            "Installing collected packages: mlens\n",
            "Successfully installed mlens-0.2.3\n",
            "\n",
            "Fitting 2 layers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[MLENS] backend: threading\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing layer-1             "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done | 00:02:47\n",
            "Processing layer-2             done | 00:00:01\n",
            "Fit complete                        | 00:02:49\n",
            "\n",
            "Predicting 2 layers\n",
            "Processing layer-1             done | 00:00:02\n",
            "Processing layer-2             done | 00:00:00\n",
            "Predict complete                    | 00:00:04\n",
            "RMSE SL: 4.763\n"
          ]
        }
      ],
      "source": [
        "!pip install mlens\n",
        "from mlens.ensemble import SuperLearner\n",
        "# Instantiate the ensemble with 5 folds (stacking meta-learner)\n",
        "sl = SuperLearner(\n",
        "    folds=5,\n",
        "    random_state=123,\n",
        "    verbose=2,\n",
        "    backend=\"multiprocessing\",\n",
        "    n_jobs=3\n",
        ")\n",
        "\n",
        "# Add the base learners and the meta learner\n",
        "sl.add([knn, svr, rf])\n",
        "sl.add_meta(meta_learner)\n",
        "\n",
        "# Train the ensemble\n",
        "sl.fit(xtrain, ytrain)\n",
        "\n",
        "# Predict the test set\n",
        "slPred = sl.predict(xtest)\n",
        "score = mean_squared_error(ytest, slPred, squared= False)\n",
        "print(\"RMSE SL:\", \"%.3f\" % (score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xijwZpgiO2m"
      },
      "source": [
        "Not very promising. But we fit the superlearner with all the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFl5USn3e9pR",
        "outputId": "a8acf6cc-f2a6-4231-c5f9-f9c5d511719e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting 2 layers\n",
            "Processing layer-1             "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n",
            "/usr/local/lib/python3.7/dist-packages/mlens/parallel/learner.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.estimator.fit(xtemp, ytemp)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done | 00:03:23\n",
            "Processing layer-2             [LibLinear][LibLinear][LibLinear][LibLinear]done | 00:00:01\n",
            "Fit complete                        | 00:03:26\n",
            "\n",
            "Predicting 2 layers\n",
            "Processing layer-1             done | 00:00:05\n",
            "Processing layer-2             done | 00:00:00\n",
            "Predict complete                    | 00:00:06\n"
          ]
        }
      ],
      "source": [
        "# Train the ensemble\n",
        "sl.fit(X, y)\n",
        "\n",
        "# Predict the test set\n",
        "slPred = sl.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmzTp9w4P9aJ"
      },
      "source": [
        "We inspect the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTLB-PRdmXoE",
        "outputId": "6e4fc0c9-f450-4612-b810-2c8b2f905d34"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5221.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.789525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.503942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.414092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.787720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.555444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.342220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37.160007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  5221.000000\n",
              "mean      3.789525\n",
              "std       3.503942\n",
              "min       0.414092\n",
              "25%       1.787720\n",
              "50%       2.555444\n",
              "75%       4.342220\n",
              "max      37.160007"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(slPred).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i9b8AKlizPs"
      },
      "source": [
        "####XGBOOST:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTMFzpYHMctK"
      },
      "source": [
        "We try out XGBOOST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ghMjCCt-mL"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu7tQVBTMlX4"
      },
      "source": [
        "Gridsearch suggests very little changes to the default parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiViVcFdOL9y"
      },
      "outputs": [],
      "source": [
        "xgbr = xgb.XGBRegressor(verbosity = 0, eta = 0.1, max_depth=6, subsample=1)\n",
        "\n",
        "#params = {\"eta\": [0.1, 0.2, 0.3],\n",
        " #         \"max_depth\": [3, 6, 8],\n",
        "  #        \"subsample\": [0.8, 1]}\n",
        "\n",
        "#search = GridSearchCV(xgbr, params, cv=5, n_jobs=8, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "#search.fit(X, y)\n",
        "\n",
        "#search.best_params_\n",
        "#search.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHj9l4VrLYUG"
      },
      "source": [
        "Nonetheless, the GridSearchCV was not very wide in order to save time. \n",
        "\n",
        "We try a different approach to complement these results: Bayesian Search. This technique uses Bayesian optimization to try to find some structure in the search space, and through it minimizes the search time. \n",
        "\n",
        "It uses the past evaluation results to sample new candidates that are more likely to give better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bk7H-vIpd-Q",
        "outputId": "7c143cb4-c06d-4299-e734-1bd167ab43d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     || 100 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.0.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n",
            "[15:25:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "-16.90486311041289"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "xgbr = xgb.XGBRegressor()\n",
        "\n",
        "# we define the space for the parameter. for instance, \"eta\" is a real number between 0.1 and 0.5 and we want a uniform distribution as the prior.\n",
        "# params = {\"eta\": Real(0.1, 0.5, prior = \"uniform\"),\n",
        "  #        \"max_depth\": Integer(2, 8, prior = \"uniform\"),\n",
        "   #       \"subsample\": Real(0.7, 1, prior = \"uniform\")}\n",
        "\n",
        "#search = BayesSearchCV(xgbr, params, cv=5, n_jobs=8, n_iter = 10, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "#search.fit(X, y)\n",
        "\n",
        "#search.best_params_\n",
        "#search.best_score_\n",
        "\n",
        "#xgbr.fit(X,y)\n",
        "\n",
        "#LOS_pred = pd.DataFrame(xgbr.predict(X_test)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUfVJh_oNurK"
      },
      "source": [
        "Best scores were 4.15 RMSE for our simple grid search and 4.11 RSME for our Bayesian Grid Search. These are more promising than the one we got with Stacking. \n",
        "\n",
        "We use the hyperparameters suggested by BGS, fit our model and make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFEYEuaqPH7n",
        "outputId": "18a0f4a9-7b30-485a-c244-b2f3425a4d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16:42:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ],
      "source": [
        "xgbr = xgb.XGBRegressor(n_estimators = 200, eta = 0.29748707337902003, max_depth = 5, subsample = 0.7458870482611535)\n",
        "\n",
        "xgbr.fit(X,y)\n",
        "\n",
        "LOS_pred = pd.DataFrame(xgbr.predict(X_test)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Q6d9MHNIbv"
      },
      "source": [
        "Note that, since we have not set a seed, and due to the fact that we are regressing LOS that are in some cases close to zero, you might get some predictions with negative values. This will be \"manually\" corrected later on.\n",
        "\n",
        "In my experience they are at most 2, out of the 5000+."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp6ZGjtOzi6Y"
      },
      "source": [
        "####Bagging XGBOOST:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS-UbPkmDtFm"
      },
      "source": [
        "If XGBOOST by itself is nice, imagine bagging it. \n",
        "\n",
        "The grid search suggests using the exact default parameters for BaggingRegressor (in terms of bootstrap, bootstrapping features and max_samples). The higher the n_estimators, the better the results (more bootstrapped models aggregated), but also the longer it takes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InLOCflMziKT",
        "outputId": "3b4afe38-9b4a-468e-eccb-6588b1759029"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py:429: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  return column_or_1d(y, warn=True)\n",
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:  9.5min remaining: 15.8min\n",
            "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed: 10.8min remaining:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed: 10.8min finished\n",
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done   3 out of   8 | elapsed:    0.9s remaining:    1.5s\n",
            "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    1.2s finished\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "baggedXGB = BaggingRegressor(base_estimator = xgbr, n_estimators = 20, verbose=2, bootstrap=True, bootstrap_features=False, max_samples=1.0, n_jobs = 8)\n",
        "\n",
        "#Grid Search:\n",
        "#baggedXGB = BaggingRegressor(base_estimator = xgbr, n_estimators = 5, verbose=2, n_jobs = 8)\n",
        "#params = {\"max_samples\": [0.8, 1.0],\n",
        "#        \"bootstrap\": [True],\n",
        "#        \"bootstrap_features\": [True, False]}\n",
        "\n",
        "\n",
        "#search = GridSearchCV(baggedXGB, params, cv=3, n_jobs=8, scoring=\"neg_mean_squared_error\")\n",
        "\n",
        "#search.fit(X, y)\n",
        "\n",
        "#search.best_params_\n",
        "#search.best_score_\n",
        "\n",
        "baggedXGB.fit(X,y)\n",
        "LOS_baggedXBG = baggedXGB.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GZWZAPrREjJ"
      },
      "source": [
        "Best score was 4.09 RMSE, which is only slightly better than the one we got with a single XBGR model, but only 5 estimators were built to keep runtimes short. \n",
        "\n",
        "The more estimators used, the higher the reduction in variance, since conceptually you are training your model with many different datasets making it less data-specific and more general. Of course, the more n_estimators, the more expensive in computational times our model becomes.\n",
        "\n",
        "We end up fitting the optimally hyperparameterized model with 20 estimators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "6eTAK_FK6m8h",
        "outputId": "aa6dd5fb-f9b3-42e2-e722-9b60b5cad458"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5221.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.748377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.242283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.737201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.813054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.624174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.389837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>34.612198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "count  5221.000000\n",
              "mean      3.748377\n",
              "std       3.242283\n",
              "min      -0.737201\n",
              "25%       1.813054\n",
              "50%       2.624174\n",
              "75%       4.389837\n",
              "max      34.612198"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(LOS_baggedXBG).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIcHRRFewptR"
      },
      "source": [
        "## To Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEUrdZdq7iK-"
      },
      "source": [
        "Since our Bagged Extreme Gradient Booster model shows the most promise, it is the one we end up coding for the kaggle submission.\n",
        "\n",
        "The other predictions were also uploaded but did worse.\n",
        "\n",
        "As stated before, some predictions might be negative, which makes sense for a regression model predicting values close to 0. We add a constraint that sets all negative values to 0.1.\n",
        "\n",
        "This does not affect significantly the kaggle score, since it is only for 1 or 2 predictions out of 5000+, and for values very close to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rAxEC847Z2AD",
        "outputId": "29774cf1-b24d-403d-dd21-21ea574d688f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>icustay_id</th>\n",
              "      <th>LOS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>208169</td>\n",
              "      <td>5.189625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>251754</td>\n",
              "      <td>9.675256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>242171</td>\n",
              "      <td>2.821512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>263035</td>\n",
              "      <td>3.666711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>279388</td>\n",
              "      <td>10.368161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5216</th>\n",
              "      <td>278087</td>\n",
              "      <td>7.519275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5217</th>\n",
              "      <td>266914</td>\n",
              "      <td>12.749612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5218</th>\n",
              "      <td>213413</td>\n",
              "      <td>1.310329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5219</th>\n",
              "      <td>286384</td>\n",
              "      <td>1.794740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5220</th>\n",
              "      <td>280741</td>\n",
              "      <td>1.443170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5221 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      icustay_id        LOS\n",
              "0         208169   5.189625\n",
              "1         251754   9.675256\n",
              "2         242171   2.821512\n",
              "3         263035   3.666711\n",
              "4         279388  10.368161\n",
              "...          ...        ...\n",
              "5216      278087   7.519275\n",
              "5217      266914  12.749612\n",
              "5218      213413   1.310329\n",
              "5219      286384   1.794740\n",
              "5220      280741   1.443170\n",
              "\n",
              "[5221 rows x 2 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = pd.read_csv('mimic_test_los.csv')\n",
        "submit = pd.DataFrame(test_data[\"icustay_id\"])\n",
        "submit[\"LOS\"] = LOS_baggedXBG #LOS_pred #slPred\n",
        "\n",
        "#regression can offer some negative values for LOS if the model predicts they will be very low. We correct that here:\n",
        "submit['LOS'] = submit['LOS'].apply(lambda x: 0.1 if x < 0 else x)\n",
        "\n",
        "#generate file to upload to kaggle\n",
        "submit.to_csv(path_or_buf='submit.csv', index=False)\n",
        "\n",
        "#show dataframe\n",
        "submit"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "JSYuwqlVxLMy",
        "DAIjfH7YwptA",
        "iunVvv5SwptE",
        "1T8J6WJAF3Is",
        "23TOaCNLwptI"
      ],
      "name": "Juan Picciotti - Decision Trees.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
